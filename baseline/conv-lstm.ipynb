{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 200, 2, 128, 64])\n",
      "Training data normalized: min=0.0, max=1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "system = \"cy\"\n",
    "x_train = np.load(f'/data5/chengjingwen/data/{system}/uv.npy')\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)  \n",
    "print(x_train.shape)\n",
    "num_trajectories, total_steps, num_var, x_dim, y_dim = x_train.shape\n",
    "\n",
    "xmin = x_train.amin(dim=(0, 1, 3, 4), keepdim=True)  \n",
    "xmax = x_train.amax(dim=(0, 1, 3, 4), keepdim=True)  \n",
    "\n",
    "\n",
    "data = (x_train - xmin) / (xmax - xmin)\n",
    "\n",
    "\n",
    "print(f\"Training data normalized: min={data.min().item()}, max={data.max().item()}\")\n",
    "\n",
    "\n",
    "# torch.save({'xmin': xmin, 'xmax': xmax}, f'/data4/chengjingwen/kdd25-main 3/data/lo/normalization_params.pth')\n",
    "\n",
    "num_train = int(num_trajectories * 0.8)  # 80%的轨迹数\n",
    "random_indices = torch.randperm(num_trajectories)[:num_train]  \n",
    "data = data[random_indices]\n",
    "num_trajectories, total_steps, num_var, x_dim, y_dim = data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class MultiStepInputDataset(Dataset):\n",
    "    def __init__(self, data, history_steps=10):\n",
    "        \"\"\"\n",
    "        data: Tensor, shape (num_trajectories, num_steps, num_variables, x_dim, y_dim)\n",
    "        history_steps: how many past steps to use as input\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.history_steps = history_steps\n",
    "        self.num_trajectories, self.num_steps, self.num_variables, self.x_dim, self.y_dim = data.shape\n",
    "\n",
    "        # 确保有足够时间步能取 history_steps + 1（因为input要10步，output是第11步）\n",
    "        if self.num_steps <= self.history_steps:\n",
    "            raise ValueError(\"num_steps must be greater than history_steps\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # 每条轨迹生成 (num_steps - history_steps) 个样本\n",
    "        return self.num_trajectories * (self.num_steps - self.history_steps)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 确定轨迹编号和在轨迹内的起点时间步\n",
    "        trajectory_idx = idx // (self.num_steps - self.history_steps)\n",
    "        time_idx = idx % (self.num_steps - self.history_steps)\n",
    "\n",
    "        # input: 连续 history_steps 个时间步，堆叠成channel\n",
    "        input_data = self.data[trajectory_idx, time_idx : time_idx + self.history_steps]  # (history_steps, num_variables, x_dim, y_dim)\n",
    "        \n",
    "\n",
    "        # target: 预测的第 history_steps 后的一个时间步\n",
    "        target_data = self.data[trajectory_idx, time_idx + self.history_steps].unsqueeze(0)  # (1, num_variables, x_dim, y_dim)\n",
    "\n",
    "        return input_data, target_data\n",
    "\n",
    "\n",
    "# train_data = data\n",
    "\n",
    "# train_dataset = MultiStepInputDataset(train_data, history_steps=10)\n",
    "\n",
    "# # 随机划分 80% train, 20% val\n",
    "# train_size = int(0.8 * len(train_dataset))\n",
    "# val_size = len(train_dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# # 打印一个batch看看\n",
    "# for inputs, targets in train_loader:\n",
    "#     print(f\"Input shape: {inputs.shape}, Target shape: {targets.shape}\")\n",
    "#     num_variables = inputs.shape[1]\n",
    "#     break  # 只打印一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convlstm import ConvLSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class my_ConvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    inputs: [B, time_step, num_var, x_dim, y_dim] or [B, num_var, x_dim, y_dim]\n",
    "    outputs: [B, pred_steps, num_var, x_dim, y_dim]\n",
    "    \"\"\"\n",
    "    def __init__(self, num_var, x_dim=128, y_dim=128, hidden_dim=128, num_layers=3, n=1):\n",
    "        super(my_ConvLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n = n  # Default prediction steps\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.num_var = num_var\n",
    "        self.cell = ConvLSTM(\n",
    "            input_dim = num_var, \n",
    "            hidden_dim = hidden_dim,\n",
    "            kernel_size = (3,3),\n",
    "            num_layers = 3,    # make sure len(hidden_dim) = num_layers\n",
    "            batch_first=True, \n",
    "            bias=True, \n",
    "            return_all_layers=False)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(in_channels=hidden_dim, out_channels=num_var, kernel_size=3, padding = 1)\n",
    "\n",
    "    def forward(self, x, n=None):\n",
    "        if n is None:  # Use default n if not provided\n",
    "            n = self.n\n",
    "            \n",
    "        if len(x.shape) == 4:   # add time dimension\n",
    "            x = x.unsqueeze(1)\n",
    "            \n",
    "        # Pass through LSTM\n",
    "        layer_output_list, last_state_list = self.cell(x)   # x: [batch_size, T, num_var, input_dim, input_dim]\n",
    "        (h,c) = last_state_list[0]\n",
    "        last_state_list = [(h, c)] * self.num_layers\n",
    "        \n",
    "        output = layer_output_list[0][:,-1,:,:]  # 最后一层layer、最后一个时间步的输出  output:[batch_size, hidden_dim, input_dim, input_dim]\n",
    "        final_output = self.final_conv(output)  # [batch_size, num_var, input_dim, input_dim]\n",
    "        y = [final_output]\n",
    "        \n",
    "        # Multi-step prediction\n",
    "        for _ in range(1, n):\n",
    "            last_output = y[-1].unsqueeze(1)  # [batch_size, 1, hidden_dim, input_dim, input_dim]\n",
    "            \n",
    "            layer_output_list, last_state_list = self.cell(last_output, last_state_list)   \n",
    "            (h,c) = last_state_list[0]\n",
    "            last_state_list = [(h, c)] * self.num_layers\n",
    "            \n",
    "            output = layer_output_list[0][:,-1,:,:]  #[batch_size, hidden_dim, input_dim, input_dim]\n",
    "            final_output = self.final_conv(output)  # [batch_size, num_var, input_dim, input_dim]\n",
    "            \n",
    "            y.append(final_output)\n",
    "        final_outputs = torch.stack(y, dim=1).reshape(-1, self.num_var, self.x_dim, self.y_dim)\n",
    "        # y_tensor: [batch_size, n, hidden_dim, input_dim, input_dim]\n",
    "       \n",
    "        # Return last prediction and all predictions\n",
    "        return final_outputs.reshape(-1, n, self.num_var, self.x_dim, self.y_dim)  # [batch_size, n, num_var, input_dim, input_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数量: 2.96 M\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "x = torch.rand((32, 10, 2, 128, 128))\n",
    "convlstm = my_ConvLSTM(2, 128, 256)   #\n",
    "final_output = convlstm(x)\n",
    "num_params = sum(p.numel() for p in convlstm.parameters())\n",
    "print(f\"模型总参数量: {num_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 2, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(final_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 10, 3, 128, 128]), Target shape: torch.Size([8, 1, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data3/chengjingwen/.conda/envs/lmenv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "100%|██████████| 720/720 [02:15<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Reconstruction Loss: 1.30e-02\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Reconstruction Loss: 3.65e-04\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Reconstruction Loss: 2.56e-04\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Reconstruction Loss: 2.11e-04\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Reconstruction Loss: 1.85e-04\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Reconstruction Loss: 1.57e-04\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Reconstruction Loss: 1.33e-04\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Reconstruction Loss: 1.18e-04\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Reconstruction Loss: 9.37e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Reconstruction Loss: 8.09e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Reconstruction Loss: 6.78e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Reconstruction Loss: 5.72e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Reconstruction Loss: 5.55e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Reconstruction Loss: 5.90e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Reconstruction Loss: 3.57e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Reconstruction Loss: 3.94e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [01:56<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Reconstruction Loss: 3.48e-05\n",
      "learning rate for lstm:0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 388/720 [01:02<00:53,  6.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     51\u001b[39m total_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (input_data, target_data) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total = \u001b[38;5;28mlen\u001b[39m(train_loader)):\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     input_data = input_data.to(device)  \u001b[38;5;66;03m# Shape: [batch_size, num_variables, x_dim, y_dim]\u001b[39;00m\n\u001b[32m     56\u001b[39m     target_data = target_data.to(device)  \u001b[38;5;66;03m# Shape: [batch_size, pred_step, num_variables, x_dim, y_dim]\u001b[39;00m\n\u001b[32m     59\u001b[39m     pred_data = Conv_LSTM(input_data)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "x_dim = 128\n",
    "y_dim = 128\n",
    "input_step = 10\n",
    "pred_step = 1\n",
    "num_epochs = 30\n",
    "batch_size = 8\n",
    "device = \"cuda:7\" \n",
    "lr_min = 1e-5\n",
    "hidden_dim = 64\n",
    "num_layers = 3\n",
    "train_data = data\n",
    "\n",
    "train_dataset = MultiStepInputDataset(train_data, history_steps=10)\n",
    "\n",
    "# 随机划分 80% train, 20% val\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 打印一个batch看看\n",
    "for inputs, targets in train_loader:\n",
    "    print(f\"Input shape: {inputs.shape}, Target shape: {targets.shape}\")\n",
    "    num_variables = inputs.shape[1]\n",
    "    break  # 只打印一次\n",
    "\n",
    "\n",
    "Conv_LSTM = my_ConvLSTM(num_var, x_dim=x_dim, y_dim = y_dim, hidden_dim=hidden_dim, num_layers=num_layers, n=pred_step).to(device)\n",
    "\n",
    "\n",
    "optimizer = Adam(list(Conv_LSTM.parameters()), lr=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    Conv_LSTM.train()\n",
    "   \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (input_data, target_data) in tqdm(enumerate(train_loader), total = len(train_loader)):\n",
    "        \n",
    "        input_data = input_data.to(device)  # Shape: [batch_size, num_variables, x_dim, y_dim]\n",
    "        target_data = target_data.to(device)  # Shape: [batch_size, pred_step, num_variables, x_dim, y_dim]\n",
    "        \n",
    "        \n",
    "        pred_data = Conv_LSTM(input_data)\n",
    "        \n",
    "        \n",
    "        loss = criterion(pred_data, target_data)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    scheduler.step(avg_loss)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Reconstruction Loss: {avg_loss:.2e}\")\n",
    "    print(f\"learning rate for lstm:{optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "    if optimizer.param_groups[0]['lr'] < lr_min:\n",
    "        print(f\"Learning rate below threshold ({lr_min}). Stopping early.\")\n",
    "        break    \n",
    "       \n",
    "\n",
    "    \n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "\n",
    "#### 为啥这么慢！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Reconstruction Loss: 1.60e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [2/60], Reconstruction Loss: 1.57e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [3/60], Reconstruction Loss: 1.57e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [4/60], Reconstruction Loss: 1.56e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [5/60], Reconstruction Loss: 1.56e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [6/60], Reconstruction Loss: 1.56e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [7/60], Reconstruction Loss: 1.56e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [8/60], Reconstruction Loss: 1.56e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [9/60], Reconstruction Loss: 1.56e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [10/60], Reconstruction Loss: 1.55e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [11/60], Reconstruction Loss: 1.56e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [12/60], Reconstruction Loss: 1.55e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [13/60], Reconstruction Loss: 1.55e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [14/60], Reconstruction Loss: 1.55e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [15/60], Reconstruction Loss: 1.54e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [16/60], Reconstruction Loss: 1.54e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [17/60], Reconstruction Loss: 1.54e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [18/60], Reconstruction Loss: 1.54e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [19/60], Reconstruction Loss: 1.53e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [20/60], Reconstruction Loss: 1.53e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [21/60], Reconstruction Loss: 1.52e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [22/60], Reconstruction Loss: 1.52e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [23/60], Reconstruction Loss: 1.52e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [24/60], Reconstruction Loss: 1.51e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [25/60], Reconstruction Loss: 1.51e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [26/60], Reconstruction Loss: 1.50e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [27/60], Reconstruction Loss: 1.50e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [28/60], Reconstruction Loss: 1.49e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [29/60], Reconstruction Loss: 1.49e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [30/60], Reconstruction Loss: 1.48e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [31/60], Reconstruction Loss: 1.48e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [32/60], Reconstruction Loss: 1.47e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [33/60], Reconstruction Loss: 1.47e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [34/60], Reconstruction Loss: 1.47e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [35/60], Reconstruction Loss: 1.46e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [36/60], Reconstruction Loss: 1.46e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [37/60], Reconstruction Loss: 1.45e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [38/60], Reconstruction Loss: 1.45e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [39/60], Reconstruction Loss: 1.44e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [40/60], Reconstruction Loss: 1.44e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [41/60], Reconstruction Loss: 1.44e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [42/60], Reconstruction Loss: 1.43e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [43/60], Reconstruction Loss: 1.43e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [44/60], Reconstruction Loss: 1.42e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [45/60], Reconstruction Loss: 1.42e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [46/60], Reconstruction Loss: 1.42e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [47/60], Reconstruction Loss: 1.41e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [48/60], Reconstruction Loss: 1.41e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [49/60], Reconstruction Loss: 1.40e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [50/60], Reconstruction Loss: 1.40e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [51/60], Reconstruction Loss: 1.40e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [52/60], Reconstruction Loss: 1.39e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [53/60], Reconstruction Loss: 1.39e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [54/60], Reconstruction Loss: 1.38e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [55/60], Reconstruction Loss: 1.38e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [56/60], Reconstruction Loss: 1.38e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [57/60], Reconstruction Loss: 1.37e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [58/60], Reconstruction Loss: 1.37e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [59/60], Reconstruction Loss: 1.36e-03\n",
      "learning rate for lstm:0.0001\n",
      "Epoch [60/60], Reconstruction Loss: 1.36e-03\n",
      "learning rate for lstm:0.0001\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# num_epochs = 60\n",
    "\n",
    "# optimizer = Adam(list(Conv_LSTM.parameters()), lr=1e-4)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     Conv_LSTM.train()\n",
    "   \n",
    "#     total_loss = 0.0\n",
    "    \n",
    "#     for batch_idx, (input_data, target_data) in enumerate(train_loader):\n",
    "#        \n",
    "#         input_data = input_data.to(device)  # Shape: [batch_size, num_variables, x_dim, y_dim]\n",
    "#         target_data = target_data.to(device)  # Shape: [batch_size, pred_step, num_variables, x_dim, y_dim]\n",
    "        \n",
    "        \n",
    "#         pred_data = Conv_LSTM(input_data)\n",
    "        \n",
    "#         \n",
    "#         loss = criterion(pred_data, target_data)\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#     avg_loss = total_loss / len(train_loader)\n",
    "#     scheduler.step(avg_loss)\n",
    "#     print(f\"Epoch [{epoch + 1}/{num_epochs}], Reconstruction Loss: {avg_loss:.2e}\")\n",
    "#     print(f\"learning rate for lstm:{optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "#     if optimizer.param_groups[0]['lr'] < lr_min:\n",
    "#         print(f\"Learning rate below threshold ({lr_min}). Stopping early.\")\n",
    "#         break    \n",
    "       \n",
    "\n",
    "    \n",
    "\n",
    "# print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# torch.save(Conv_LSTM.state_dict(), f\"/data3/chengjingwen/diffusion-mdpnet/trained_model/baseline/{system}/convlstm_{hidden_dim}_{num_layers}.pth\")\n",
    "\n",
    "# print(\"Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data normalized: min=0.0, max=0.913608968257904\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "system = \"sevir_tem\"\n",
    "x_test = np.load(f'/data5/chengjingwen/{system}/uv_test.npy')\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)  # 转换为 Tensor\n",
    "\n",
    "x_train = np.load(f'/data5/chengjingwen/{system}/uv.npy')\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)  \n",
    "\n",
    "num_trajectories, total_steps, num_var, x_dim, y_dim = x_test.shape\n",
    "\n",
    "xmin = x_train.amin(dim=(0, 1, 3, 4), keepdim=True)  \n",
    "xmax = x_train.amax(dim=(0, 1, 3, 4), keepdim=True)  \n",
    "del x_train\n",
    "\n",
    "x_test_normalized = (x_test - xmin) / (xmax - xmin)\n",
    "\n",
    "\n",
    "print(f\"Test data normalized: min={x_test_normalized.min().item()}, max={x_test_normalized.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3251899/1648864482.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Conv_LSTM.load_state_dict(torch.load(f\"/data3/chengjingwen/diffusion-mdpnet/trained_model/baseline/{system}/convlstm_{hidden_dim}_{num_layers}.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n",
      "torch.Size([50, 49, 1, 128, 128])\n",
      "now for 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data3/chengjingwen/.conda/envs/lmenv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `spectral_angle_mapper` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `spectral_angle_mapper` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now for 1\n",
      "now for 2\n",
      "now for 3\n",
      "now for 4\n",
      "now for 5\n",
      "now for 6\n",
      "now for 7\n",
      "now for 8\n",
      "now for 9\n",
      "now for 10\n",
      "now for 11\n",
      "now for 12\n",
      "now for 13\n",
      "now for 14\n",
      "now for 15\n",
      "now for 16\n",
      "now for 17\n",
      "now for 18\n",
      "now for 19\n",
      "now for 20\n",
      "now for 21\n",
      "now for 22\n",
      "now for 23\n",
      "now for 24\n",
      "now for 25\n",
      "now for 26\n",
      "now for 27\n",
      "now for 28\n",
      "now for 29\n",
      "now for 30\n",
      "now for 31\n",
      "now for 32\n",
      "now for 33\n",
      "now for 34\n",
      "now for 35\n",
      "now for 36\n",
      "now for 37\n",
      "now for 38\n",
      "now for 39\n",
      "now for 40\n",
      "now for 41\n",
      "now for 42\n",
      "now for 43\n",
      "now for 44\n",
      "now for 45\n",
      "now for 46\n",
      "now for 47\n",
      "now for 48\n",
      "now for 49\n",
      "NMSE Mean: 0.07461631279438734\n",
      "NMSE Std: 0.03550012458813356\n",
      "SSIM Mean: 0.7287774604558944\n",
      "SSIM Std: 0.1195255062482466\n",
      "RMSE Mean: 0.13682179391384125\n",
      "RMSE Std: 0.02776724391270291\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "pred_step = 1  \n",
    "pred_steps = 30\n",
    "start_time = 10\n",
    "\n",
    "def compute_nmse(predictions, targets):\n",
    "    \"\"\"计算 NMSE\"\"\"\n",
    "    return torch.mean(((predictions - targets) ** 2)) / torch.mean((targets ** 2))\n",
    "\n",
    "def compute_rmse(predictions, targets):\n",
    "    \"\"\"计算 RMSE\"\"\"\n",
    "    mse = torch.mean((predictions - targets) ** 2)\n",
    "    return torch.sqrt(mse)\n",
    "\n",
    "\n",
    "def test_model(convlstm, test_data, device):\n",
    "    convlstm.eval()\n",
    "\n",
    "    num_trajectories, T, num_variables, x_dim, y_dim = test_data.shape\n",
    "\n",
    "    nmse_list = []\n",
    "    ssim_list = []\n",
    "    rmse_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for trajectory_idx in range(num_trajectories):\n",
    "            print(f\"now for {trajectory_idx}\")\n",
    "            trajectory = test_data[trajectory_idx]  # shape [100, num_variables, x_dim, y_dim]\n",
    "            \n",
    "            targets = trajectory[start_time :start_time + pred_steps].to(device)  \n",
    "\n",
    "        \n",
    "            predictions = torch.zeros((pred_steps, num_variables, x_dim, y_dim)).to(device)\n",
    "\n",
    "            for t in range(0,pred_steps,pred_step):  \n",
    "                if(t==0):\n",
    "                    input_data = trajectory[start_time-10:start_time].unsqueeze(0).to(device)  # shape: [1, 10, num_variables, x_dim, y_dim]\n",
    "                # else: \n",
    "                #     input_data = preds[-1, :, :, :].unsqueeze(0)\n",
    "                    \n",
    "                preds = Conv_LSTM(input_data)  # shape: [1, pred_step, num_variables, x_dim, y_dim]\n",
    "                input_data = input_data[:,1:]\n",
    "                input_data = torch.cat([input_data, preds], dim = 1)\n",
    "                \n",
    "                predictions[t : t + pred_step] = preds\n",
    "                \n",
    "                # ipdb.set_trace()\n",
    "            # if trajectory_idx == 0:\n",
    "            #     for t in range(50):\n",
    "            #         plt.figure(figsize=(12, 4))\n",
    "\n",
    "            #         # Ground Truth\n",
    "            #         plt.subplot(131)\n",
    "            #         plt.title(f\"Ground Truth (step={ t + 1})\")\n",
    "            #         plt.imshow(targets[t, 0].detach().cpu().numpy(), cmap=\"jet\", vmin=-1, vmax=1)  \n",
    "            #         plt.colorbar()\n",
    "\n",
    "            #         # Prediction\n",
    "            #         plt.subplot(132)\n",
    "            #         plt.title(\"Prediction\")\n",
    "            #         plt.imshow(predictions[t, 0].detach().cpu().numpy(), cmap=\"jet\", vmin=-1, vmax=1)  \n",
    "            #         plt.colorbar()\n",
    "\n",
    "            #         # Difference and MSE\n",
    "            #         mse = torch.mean((targets[t, 0] - predictions[t, 0]) ** 2).item()\n",
    "            #         plt.subplot(133)\n",
    "            #         plt.title(f\"Difference (MSE={mse:.5f})\")\n",
    "            #         plt.imshow(torch.abs(targets[t, 0] - predictions[t, 0]).detach().cpu().numpy(), cmap=\"jet\")\n",
    "            #         plt.colorbar()\n",
    "\n",
    "            #         plt.show()\n",
    "            #         clear_output(wait=True)  \n",
    "                \n",
    "\n",
    "        \n",
    "            ssim_values = ssim(predictions, targets, data_range=1.0).item() \n",
    "            nmse_trajectory = compute_nmse(predictions, targets).item() \n",
    "            rmse_trajectory = compute_rmse(predictions, targets).item()  \n",
    "\n",
    "            nmse_list.append(nmse_trajectory)\n",
    "            ssim_list.append(ssim_values)\n",
    "            rmse_list.append(rmse_trajectory)\n",
    "\n",
    "    \n",
    "        nmse_mean, nmse_std = np.mean(nmse_list), np.std(nmse_list)\n",
    "        ssim_mean, ssim_std = np.mean(ssim_list), np.std(ssim_list)\n",
    "        rmse_mean, rmse_std = np.mean(rmse_list), np.std(rmse_list)\n",
    "\n",
    "        return {\n",
    "            \"NMSE_mean\": nmse_mean,\n",
    "            \"NMSE_std\": nmse_std,\n",
    "            \"SSIM_mean\": ssim_mean,\n",
    "            \"SSIM_std\": ssim_std,\n",
    "            \"RMSE_mean\": rmse_mean,\n",
    "            \"RMSE_std\": rmse_std\n",
    "        }\n",
    "\n",
    "with torch.no_grad():\n",
    "    device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    hidden_dim = 128\n",
    "    num_layers = 3\n",
    "    x_dim = 128\n",
    "    y_dim = 128\n",
    "    Conv_LSTM = my_ConvLSTM(num_var, x_dim=x_dim, y_dim = y_dim, hidden_dim=hidden_dim, num_layers=3, n=pred_step).to(device)\n",
    "    Conv_LSTM.load_state_dict(torch.load(f\"/data3/chengjingwen/diffusion-mdpnet/trained_model/baseline/{system}/convlstm_{hidden_dim}_{num_layers}.pth\"))\n",
    "    Conv_LSTM.eval()\n",
    "\n",
    "    print(\"Models loaded successfully!\")\n",
    "\n",
    "\n",
    "    test_data = x_test_normalized.to(device)  \n",
    "    print(test_data.shape)\n",
    "\n",
    "    results = test_model(Conv_LSTM, test_data, device)\n",
    "\n",
    "\n",
    "    print(f\"NMSE Mean: {results['NMSE_mean']}\")\n",
    "    print(f\"NMSE Std: {results['NMSE_std']}\")\n",
    "    print(f\"SSIM Mean: {results['SSIM_mean']}\")\n",
    "    print(f\"SSIM Std: {results['SSIM_std']}\")\n",
    "    print(f\"RMSE Mean: {results['RMSE_mean']}\")\n",
    "    print(f\"RMSE Std: {results['RMSE_std']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数量: 0.74 M\n"
     ]
    }
   ],
   "source": [
    "model = Conv_LSTM.to(\"cuda:3\")\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {num_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 50, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
