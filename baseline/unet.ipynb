{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "def set_cpu_num(cpu_num):\n",
    "    import os\n",
    "    import torch\n",
    "    if cpu_num <= 0: return\n",
    "    \n",
    "    os.environ ['OMP_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ ['OPENBLAS_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ ['MKL_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ ['VECLIB_MAXIMUM_THREADS'] = str(cpu_num)\n",
    "    os.environ ['NUMEXPR_NUM_THREADS'] = str(cpu_num)\n",
    "    torch.set_num_threads(cpu_num)\n",
    "set_cpu_num(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100, 2, 64, 64])\n",
      "Training data normalized: min=0.0, max=1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_train = np.load(f'/data5/chengjingwen/lo/uv.npy')\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)  \n",
    "print(x_train.shape)\n",
    "num_trajectories, total_steps, num_var, x_dim, y_dim = x_train.shape\n",
    "\n",
    "xmin = x_train.amin(dim=(0, 1, 3, 4), keepdim=True)  \n",
    "xmax = x_train.amax(dim=(0, 1, 3, 4), keepdim=True)  \n",
    "\n",
    "\n",
    "data = (x_train - xmin) / (xmax - xmin)\n",
    "\n",
    "\n",
    "print(f\"Training data normalized: min={data.min().item()}, max={data.max().item()}\")\n",
    "\n",
    "num_train = int(num_trajectories * 0.8)  # 80%的轨迹数\n",
    "random_indices = torch.randperm(num_trajectories)[:num_train]  \n",
    "data = data[random_indices]\n",
    "num_trajectories, total_steps, num_var, x_dim, y_dim = data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 2, 64, 64]), Target shape: torch.Size([32, 5, 2, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class SingleStepDataset(Dataset):\n",
    "    def __init__(self, data, pred_step):\n",
    "        \"\"\"\n",
    "        data: Tensor, shape (num_trajectories, num_steps, num_variables, x_dim, y_dim)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.num_trajectories, self.num_steps, self.num_variables, self.x_dim, self.y_dim = data.shape\n",
    "        self.pred_step = pred_step\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        # 每条轨迹生成 num_steps // self.pred_step + 1 个样本\n",
    "        return self.num_trajectories * (self.num_steps // (self.pred_step + 1))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        trajectory_idx = idx // (self.num_steps // (self.pred_step + 1))\n",
    "        time_idx = (idx % (self.num_steps // (self.pred_step + 1))) * (self.pred_step + 1)  \n",
    "\n",
    "        \n",
    "        input_data = self.data[trajectory_idx, time_idx]  # (num_variables, x_dim, y_dim)\n",
    "\n",
    "       \n",
    "        target_data = self.data[trajectory_idx, time_idx + 1 : time_idx+self.pred_step+1]  # (num_variables, x_dim, y_dim)\n",
    "\n",
    "        return input_data, target_data\n",
    "\n",
    "train_data = data\n",
    "pred_step = 5\n",
    "\n",
    "train_dataset = SingleStepDataset(train_data, pred_step = pred_step)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    print(f\"Input shape: {inputs.shape}, Target shape: {targets.shape}\")\n",
    "    num_variables = inputs.shape[1]\n",
    "    break  # 仅打印第一个 batch 的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class UNet2d(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32, pred_step=5):\n",
    "        super().__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet2d._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet2d._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet2d._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet2d._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet2d._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet2d._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet2d._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet2d._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet2d._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "        self.n = pred_step\n",
    "\n",
    "    def _forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return self.conv(dec1)\n",
    "    \n",
    "    def forward(self, x, n=None):\n",
    "        if n is None:  # Use default n if not provided\n",
    "            n = self.n\n",
    "            \n",
    "        y1 = self._forward(x)   # x: [batch_size, hidden_dim, input_dim, input_dim]\n",
    "        y = [y1]\n",
    "        \n",
    "        # Multi-step prediction\n",
    "        for _ in range(1, n):\n",
    "            last_output = y[-1]  # [batch_size, hidden_dim, input_dim, input_dim]\n",
    "            output = self._forward(last_output)   \n",
    "            y.append(output)\n",
    "        final_outputs = torch.stack(y, dim=1) # [batch_size, n, hidden_dim, input_dim, input_dim]\n",
    "       \n",
    "        # Return last prediction and all predictions\n",
    "        return final_outputs  # [batch_size, n, num_var, input_dim, input_dim]\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"tanh1\", nn.Tanh()),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"tanh2\", nn.Tanh()),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数量: 7.76 M\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "x = torch.rand((32, 2, 64, 64))\n",
    "model = UNet2d(in_channels=2, out_channels=2, init_features=32, pred_step=5)\n",
    "final_output = model(x)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {num_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5, 2, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(final_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Pred Loss: 0.20459\n",
      "Epoch [2/100], Pred Loss: 0.11358\n",
      "Epoch [3/100], Pred Loss: 0.03553\n",
      "Epoch [4/100], Pred Loss: 0.00996\n",
      "Epoch [5/100], Pred Loss: 0.00717\n",
      "Epoch [6/100], Pred Loss: 0.00391\n",
      "Epoch [7/100], Pred Loss: 0.00352\n",
      "Epoch [8/100], Pred Loss: 0.00332\n",
      "Epoch [9/100], Pred Loss: 0.00320\n",
      "Epoch [10/100], Pred Loss: 0.00267\n",
      "Epoch [11/100], Pred Loss: 0.00229\n",
      "Epoch [12/100], Pred Loss: 0.00272\n",
      "Epoch [13/100], Pred Loss: 0.00326\n",
      "Epoch [14/100], Pred Loss: 0.00359\n",
      "Epoch [15/100], Pred Loss: 0.00239\n",
      "Epoch [16/100], Pred Loss: 0.00254\n",
      "Epoch [17/100], Pred Loss: 0.00230\n",
      "Epoch [18/100], Pred Loss: 0.00217\n",
      "Epoch [19/100], Pred Loss: 0.00205\n",
      "Epoch [20/100], Pred Loss: 0.00166\n",
      "Epoch [21/100], Pred Loss: 0.00236\n",
      "Epoch [22/100], Pred Loss: 0.00249\n",
      "Epoch [23/100], Pred Loss: 0.00210\n",
      "Epoch [24/100], Pred Loss: 0.00186\n",
      "Epoch [25/100], Pred Loss: 0.00231\n",
      "Epoch [26/100], Pred Loss: 0.00201\n",
      "Epoch [27/100], Pred Loss: 0.00173\n",
      "Epoch [28/100], Pred Loss: 0.00196\n",
      "Epoch [29/100], Pred Loss: 0.00184\n",
      "Epoch [30/100], Pred Loss: 0.00173\n",
      "Epoch [31/100], Pred Loss: 0.00185\n",
      "Epoch [32/100], Pred Loss: 0.00180\n",
      "Epoch [33/100], Pred Loss: 0.00190\n",
      "Epoch [34/100], Pred Loss: 0.00158\n",
      "Epoch [35/100], Pred Loss: 0.00163\n",
      "Epoch [36/100], Pred Loss: 0.00179\n",
      "Epoch [37/100], Pred Loss: 0.00170\n",
      "Epoch [38/100], Pred Loss: 0.00262\n",
      "Epoch [39/100], Pred Loss: 0.00174\n",
      "Epoch [40/100], Pred Loss: 0.00165\n",
      "Epoch [41/100], Pred Loss: 0.00189\n",
      "Epoch [42/100], Pred Loss: 0.00183\n",
      "Epoch [43/100], Pred Loss: 0.00162\n",
      "Epoch [44/100], Pred Loss: 0.00174\n",
      "Epoch [45/100], Pred Loss: 0.00180\n",
      "Epoch [46/100], Pred Loss: 0.00146\n",
      "Epoch [47/100], Pred Loss: 0.00187\n",
      "Epoch [48/100], Pred Loss: 0.00195\n",
      "Epoch [49/100], Pred Loss: 0.00171\n",
      "Epoch [50/100], Pred Loss: 0.00230\n",
      "Epoch [51/100], Pred Loss: 0.00180\n",
      "Epoch [52/100], Pred Loss: 0.00220\n",
      "Epoch [53/100], Pred Loss: 0.00186\n",
      "Epoch [54/100], Pred Loss: 0.00161\n",
      "Epoch [55/100], Pred Loss: 0.00188\n",
      "Epoch [56/100], Pred Loss: 0.00205\n",
      "Epoch [57/100], Pred Loss: 0.00136\n",
      "Epoch [58/100], Pred Loss: 0.00168\n",
      "Epoch [59/100], Pred Loss: 0.00155\n",
      "Epoch [60/100], Pred Loss: 0.00121\n",
      "Epoch [61/100], Pred Loss: 0.00182\n",
      "Epoch [62/100], Pred Loss: 0.00139\n",
      "Epoch [63/100], Pred Loss: 0.00164\n",
      "Epoch [64/100], Pred Loss: 0.00183\n",
      "Epoch [65/100], Pred Loss: 0.00159\n",
      "Epoch [66/100], Pred Loss: 0.00144\n",
      "Epoch [67/100], Pred Loss: 0.00146\n",
      "Epoch [68/100], Pred Loss: 0.00139\n",
      "Epoch [69/100], Pred Loss: 0.00134\n",
      "Epoch [70/100], Pred Loss: 0.00192\n",
      "Epoch [71/100], Pred Loss: 0.00128\n",
      "Epoch [72/100], Pred Loss: 0.00141\n",
      "Epoch [73/100], Pred Loss: 0.00177\n",
      "Epoch [74/100], Pred Loss: 0.00179\n",
      "Epoch [75/100], Pred Loss: 0.00209\n",
      "Epoch [76/100], Pred Loss: 0.00116\n",
      "Epoch [77/100], Pred Loss: 0.00114\n",
      "Epoch [78/100], Pred Loss: 0.00163\n",
      "Epoch [79/100], Pred Loss: 0.00167\n",
      "Epoch [80/100], Pred Loss: 0.00140\n",
      "Epoch [81/100], Pred Loss: 0.00195\n",
      "Epoch [82/100], Pred Loss: 0.00174\n",
      "Epoch [83/100], Pred Loss: 0.00150\n",
      "Epoch [84/100], Pred Loss: 0.00163\n",
      "Epoch [85/100], Pred Loss: 0.00147\n",
      "Epoch [86/100], Pred Loss: 0.00164\n",
      "Epoch [87/100], Pred Loss: 0.00147\n",
      "Epoch [88/100], Pred Loss: 0.00132\n",
      "Epoch [89/100], Pred Loss: 0.00149\n",
      "Epoch [90/100], Pred Loss: 0.00175\n",
      "Epoch [91/100], Pred Loss: 0.00156\n",
      "Epoch [92/100], Pred Loss: 0.00128\n",
      "Epoch [93/100], Pred Loss: 0.00130\n",
      "Epoch [94/100], Pred Loss: 0.00155\n",
      "Epoch [95/100], Pred Loss: 0.00176\n",
      "Epoch [96/100], Pred Loss: 0.00122\n",
      "Epoch [97/100], Pred Loss: 0.00139\n",
      "Epoch [98/100], Pred Loss: 0.00152\n",
      "Epoch [99/100], Pred Loss: 0.00184\n",
      "Epoch [100/100], Pred Loss: 0.00160\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "input_step = 1\n",
    "pred_step = 5\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "device = \"cuda:3\" \n",
    "\n",
    "# 模型\n",
    "model = UNet2d(in_channels=2, out_channels=2, init_features=32, pred_step=pred_step).to(device)\n",
    "\n",
    "# 优化器\n",
    "optimizer = Adam(list(model.parameters()), lr=1e-3)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (input_data, target_data) in enumerate(train_loader):\n",
    "        input_data = input_data.to(device)  # Shape: [batch_size, num_variables, x_dim, y_dim]\n",
    "        target_data = target_data.to(device)  # Shape: [batch_size, pred_step, num_variables, x_dim, y_dim]\n",
    "        \n",
    "        pred_data = model(input_data)\n",
    "        loss = criterion(pred_data, target_data)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Pred Loss: {avg_loss:.5f}\")\n",
    "    \n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data normalized: min=-0.00329780881293118, max=1.0405967235565186\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_test = np.load(f'data/lo/uv_test.npy')\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "x_test_normalized = (x_test - xmin) / (xmax - xmin)\n",
    "\n",
    "print(f\"Test data normalized: min={x_test_normalized.min().item()}, max={x_test_normalized.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/data4/liruikun/.conda/envs/SimBackbone/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `spectral_angle_mapper` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `spectral_angle_mapper` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n",
      "100%|██████████| 50/50 [00:14<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE Mean: 0.18125465273857116\n",
      "NMSE Std: 0.06355004722925543\n",
      "SSIM Mean: 0.5855060821771622\n",
      "SSIM Std: 0.08082063331799154\n",
      "RMSE Mean: 0.16975272223353385\n",
      "RMSE Std: 0.028388472743270377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "pred_steps = 99\n",
    "\n",
    "def compute_nmse(predictions, targets):\n",
    "    \"\"\"计算 NMSE\"\"\"\n",
    "    return torch.mean(((predictions - targets) ** 2)) / torch.mean((targets ** 2))\n",
    "\n",
    "def compute_rmse(predictions, targets):\n",
    "    \"\"\"计算 RMSE\"\"\"\n",
    "    mse = torch.mean((predictions - targets) ** 2)\n",
    "    return torch.sqrt(mse)\n",
    "\n",
    "\n",
    "def test_model(convlstm, test_data, device):\n",
    "    convlstm.eval()\n",
    "\n",
    "    num_trajectories, T, num_variables, x_dim, y_dim = test_data.shape\n",
    "\n",
    "    nmse_list = []\n",
    "    ssim_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for trajectory_idx in tqdm(range(num_trajectories)):\n",
    "        trajectory = test_data[trajectory_idx]  # shape [100, num_variables, x_dim, y_dim]\n",
    "        start_time = 0\n",
    "        targets = trajectory[start_time + 1:start_time + 1 + pred_steps].to(device)  \n",
    "        predictions = model(trajectory[:1], n=pred_steps).squeeze(0) # shape: [pred_steps, num_variables, x_dim, y_dim]\n",
    "\n",
    "        # if trajectory_idx == 0:\n",
    "        #     for t in range(pred_steps):\n",
    "        #         plt.figure(figsize=(12, 4))\n",
    "\n",
    "        #         # Ground Truth\n",
    "        #         plt.subplot(131)\n",
    "        #         plt.title(f\"Ground Truth (step={ t + 1})\")\n",
    "        #         plt.imshow(targets[t, 0].detach().cpu().numpy(), cmap=\"jet\", vmin=-1, vmax=1)  # 第一个变量的真值\n",
    "        #         plt.colorbar()\n",
    "\n",
    "        #         # Prediction\n",
    "        #         plt.subplot(132)\n",
    "        #         plt.title(\"Prediction\")\n",
    "        #         plt.imshow(predictions[t, 0].detach().cpu().numpy(), cmap=\"jet\", vmin=-1, vmax=1)  # 第一个变量的预测值\n",
    "        #         plt.colorbar()\n",
    "\n",
    "        #         # Difference and MSE\n",
    "        #         mse = torch.mean((targets[t, 0] - predictions[t, 0]) ** 2).item()  # 保证两者在同一设备\n",
    "        #         plt.subplot(133)\n",
    "        #         plt.title(f\"Difference (MSE={mse:.5f})\")\n",
    "        #         plt.imshow(torch.abs(targets[t, 0] - predictions[t, 0]).detach().cpu().numpy(), cmap=\"jet\")\n",
    "        #         plt.colorbar()\n",
    "\n",
    "        #         plt.show()\n",
    "        #         clear_output(wait=True)  # 显示当前时间步，清除上一时间步\n",
    "            \n",
    "\n",
    "      \n",
    "        ssim_values = ssim(predictions, targets, data_range=1.0).item()  # SSIM\n",
    "        nmse_trajectory = compute_nmse(predictions, targets).item()  # NMSE\n",
    "        rmse_trajectory = compute_rmse(predictions, targets).item()  # RMSE\n",
    "\n",
    "        nmse_list.append(nmse_trajectory)\n",
    "        ssim_list.append(ssim_values)\n",
    "        rmse_list.append(rmse_trajectory)\n",
    "   \n",
    "    nmse_mean, nmse_std = np.mean(nmse_list), np.std(nmse_list)\n",
    "    ssim_mean, ssim_std = np.mean(ssim_list), np.std(ssim_list)\n",
    "    rmse_mean, rmse_std = np.mean(rmse_list), np.std(rmse_list)\n",
    "\n",
    "    return {\n",
    "        \"NMSE_mean\": nmse_mean,\n",
    "        \"NMSE_std\": nmse_std,\n",
    "        \"SSIM_mean\": ssim_mean,\n",
    "        \"SSIM_std\": ssim_std,\n",
    "        \"RMSE_mean\": rmse_mean,\n",
    "        \"RMSE_std\": rmse_std\n",
    "    }\n",
    "\n",
    "\n",
    "test_data = x_test_normalized.to(device)\n",
    "results = test_model(model, test_data, device)\n",
    "print(f\"NMSE Mean: {results['NMSE_mean']}\")\n",
    "print(f\"NMSE Std: {results['NMSE_std']}\")\n",
    "print(f\"SSIM Mean: {results['SSIM_mean']}\")\n",
    "print(f\"SSIM Std: {results['SSIM_std']}\")\n",
    "print(f\"RMSE Mean: {results['RMSE_mean']}\")\n",
    "print(f\"RMSE Std: {results['RMSE_std']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SimBackbone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
