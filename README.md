# ğŸŒŠ MDPNet: Multiscale Diffusion Autoencoder for Complex Systems

Thank you for reviewing our **KDD 2025** manuscript: ğŸ“„ *"Predicting the Dynamics of Complex Systems via Multiscale Diffusion Autoencoder"*

This repository contains the implementation of **MDPNet**, a novel approach for learning and predicting the evolution of complex dynamical systems using multiscale diffusion-based autoencoders.

![image](assets/SparseDiff.pdf)




## ğŸš€ Quick Start

### ğŸ“¦ Required Dependencies

Ensure the following packages are installed before running the code:

```
pip install tqdm yaml torch torchdiffeq ema_pytorch
```





### ğŸƒ Running the Model (Example: GS System)

1ï¸âƒ£ **Download Dataset** ğŸ“‚: [Google Drive](https://drive.google.com/file/d/17-GSDZN4olVQaqBDbHzQq-UAhlwfGHoh/view?usp=sharing)

2ï¸âƒ£ **Run the model**:

- Single GPU / CPU:

  ```sh
  python run.py
  ```

- Multi-GPU (with AMP support):

  ```sh
  python -m torch.distributed.run --master_port=25640 --nproc_per_node=8 train.py --use_amp --multi_gpu
  ```





## ğŸ“ Repository Structure

```sh
.
â”œâ”€â”€ README.md
â”œâ”€â”€ config
â”‚   â””â”€â”€ GS.yaml
â”œâ”€â”€ datasets.py
â”œâ”€â”€ model
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cEncoder.py
â”‚   â”œâ”€â”€ cPredictor.py
â”‚   â”œâ”€â”€ cUnet.py
â”‚   â”œâ”€â”€ common.py
â”‚   â””â”€â”€ mDynaDDPM.py
â”œâ”€â”€ run.py
â””â”€â”€ utils.py
```





## ğŸ“Œ Notes

- This implementation provides a **demo using the GS system** as an example. (Full version will be released after acceptance)
- Supports **both single-GPU and multi-GPU training**.
- Configuration files are stored in the `config/` directory.
- For questions regarding reproducibility or additional details, please refer to our manuscript.
